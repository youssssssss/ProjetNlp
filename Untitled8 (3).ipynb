{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "30e8d4b7e03444799345f05c725209f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d8d34163ef248acb2783dd57c58388d",
              "IPY_MODEL_b56c94aacde84ca98b1389a3144cb644",
              "IPY_MODEL_bb387137536545e3aa0e452a90f35f1e"
            ],
            "layout": "IPY_MODEL_164da97254194c3bbbb2a43e361aded2"
          }
        },
        "5d8d34163ef248acb2783dd57c58388d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_385f55505f594e80af8eb32d2873ccea",
            "placeholder": "​",
            "style": "IPY_MODEL_39a7bff8666146b9881025b2b650c0a5",
            "value": "model.safetensors: 100%"
          }
        },
        "b56c94aacde84ca98b1389a3144cb644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_836c536ad8d145b783aebf151ad8185d",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfebe80ec0b7446e99bceabb47c7d061",
            "value": 440449768
          }
        },
        "bb387137536545e3aa0e452a90f35f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b86ed2c5490479baaaea78fe3732bd4",
            "placeholder": "​",
            "style": "IPY_MODEL_160569a9cdbd4d7b9829a35d59988d2e",
            "value": " 440M/440M [00:05&lt;00:00, 82.7MB/s]"
          }
        },
        "164da97254194c3bbbb2a43e361aded2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "385f55505f594e80af8eb32d2873ccea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a7bff8666146b9881025b2b650c0a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "836c536ad8d145b783aebf151ad8185d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfebe80ec0b7446e99bceabb47c7d061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b86ed2c5490479baaaea78fe3732bd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160569a9cdbd4d7b9829a35d59988d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with preprocessing the coarse-and-fine-grained-ner-dataset.csv.\n",
        "\n",
        "Step 1: Preprocessing the Dataset\n",
        "We need to:\n",
        "\n",
        "Tokenize the text.\n",
        "Align the entity annotations with tokens."
      ],
      "metadata": {
        "id": "np3DgYUEYUJf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CVQ9iheX86f",
        "outputId": "ae6b051c-0e24-403b-d9d8-405b72a1cdfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text  \\\n",
            "0   grandes feuilles opposées, oblongues-elliptiq...   \n",
            "1   feuilles opposées, groupées à l'extrémité des...   \n",
            "2   feuilles opposées, obovées oblongues, arrondi...   \n",
            "3   arbustes  petites feuilles opposées, groupées...   \n",
            "4   arbustes  feuilles opposées ou alternes, obla...   \n",
            "\n",
            "                                              tokens  \n",
            "0  [grandes, feuilles, opposées,, oblongues-ellip...  \n",
            "1  [feuilles, opposées,, groupées, à, l'extrémité...  \n",
            "2  [feuilles, opposées,, obovées, oblongues,, arr...  \n",
            "3  [arbustes, petites, feuilles, opposées,, group...  \n",
            "4  [arbustes, feuilles, opposées, ou, alternes,, ...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_path = \"coarse-and-fine-grained-ner-dataset.csv\"\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "data['tokens'] = data['Text'].apply(lambda x: str(x).split())\n",
        "\n",
        "print(data[['Text', 'tokens']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Now that we have the tokens, the next step is to align the annotations (Coarse-grained and Fine-grained) with the tokens.\n",
        "\n",
        "Here’s the code to align annotations with tokens by converting annotations into a token-level BIO format:\n",
        "\n",
        "Step 2: Align Annotations with Tokens (BIO Format)"
      ],
      "metadata": {
        "id": "LKP_hNYVZIAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def align_annotations_with_tokens(tokens, annotations):\n",
        "    labels = ['O'] * len(tokens)\n",
        "\n",
        "    for start, end, entity in annotations:\n",
        "        for i, token in enumerate(tokens):\n",
        "            token_start = len(' '.join(tokens[:i])) + (i)\n",
        "            token_end = token_start + len(token)\n",
        "\n",
        "            if start <= token_start < end or start < token_end <= end:\n",
        "                labels[i] = f'I-{entity}' if labels[i] != 'O' else f'B-{entity}'\n",
        "\n",
        "    return labels\n",
        "\n",
        "# alignment for Coarse-grained annotations\n",
        "data['coarse_labels'] = data.apply(\n",
        "    lambda row: align_annotations_with_tokens(row['tokens'], eval(row['Coarse-grained Annotation'])),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# alignment for Fine-grained annotations\n",
        "data['fine_labels'] = data.apply(\n",
        "    lambda row: align_annotations_with_tokens(row['tokens'], eval(row['Fine-grained Annotation'])),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# displaying aligned annotations\n",
        "print(data[['tokens', 'coarse_labels', 'fine_labels']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcMjPAkcZISA",
        "outputId": "4f7014e4-7d89-499b-d317-f19c1dfe5f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              tokens  \\\n",
            "0  [grandes, feuilles, opposées,, oblongues-ellip...   \n",
            "1  [feuilles, opposées,, groupées, à, l'extrémité...   \n",
            "2  [feuilles, opposées,, obovées, oblongues,, arr...   \n",
            "3  [arbustes, petites, feuilles, opposées,, group...   \n",
            "4  [arbustes, feuilles, opposées, ou, alternes,, ...   \n",
            "\n",
            "                                       coarse_labels  \\\n",
            "0  [O, B-ORGANE, B-DESCRIPTEUR, B-DESCRIPTEUR, B-...   \n",
            "1  [B-ORGANE, B-DESCRIPTEUR, O, O, O, B-ORGANE, B...   \n",
            "2  [B-ORGANE, B-DESCRIPTEUR, O, B-DESCRIPTEUR, O,...   \n",
            "3  [B-ORGANE, O, B-ORGANE, B-DESCRIPTEUR, O, O, O...   \n",
            "4  [B-ORGANE, B-ORGANE, B-DESCRIPTEUR, O, B-DESCR...   \n",
            "\n",
            "                                         fine_labels  \n",
            "0  [O, B-ORGANE, B-DISPOSITION, B-DESCRIPTEUR, B-...  \n",
            "1  [B-ORGANE, B-DISPOSITION, O, O, O, B-ORGANE, B...  \n",
            "2  [B-ORGANE, B-DISPOSITION, O, B-FORME, O, O, B-...  \n",
            "3  [B-ORGANE, O, B-ORGANE, B-DISPOSITION, O, O, O...  \n",
            "4  [B-ORGANE, B-ORGANE, B-DISPOSITION, O, B-DISPO...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of Code:\n",
        "Input: Tokens and annotation spans (start, end, entity type).\n",
        "Output: A list of labels for each token in the BIO format (B-ENTITY, I-ENTITY, O).\n",
        "How it Works:\n",
        "For each token, calculate its character-level start and end indices.\n",
        "If a token overlaps with an annotation span, assign the appropriate label.\n",
        "Use B-ENTITY for the beginning of an entity and I-ENTITY for inside."
      ],
      "metadata": {
        "id": "bGF-x5DuZ8Jp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the tokens and their corresponding coarse_labels and fine_labels are properly aligned, the next step is to split the data into training, validation, and test sets.\n",
        "\n",
        "Step 3: Splitting Data\n",
        "We’ll split the data into three subsets:\n",
        "\n",
        "Training Set: For model training.\n",
        "Validation Set: For hyperparameter tuning.\n",
        "Test Set: For final model evaluation.\n",
        "Here’s the code for splitting the dataset:"
      ],
      "metadata": {
        "id": "y7klJANoZ9kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data['tokens']\n",
        "y_coarse = data['coarse_labels']\n",
        "y_fine = data['fine_labels']\n",
        "\n",
        "X_train, X_temp, y_coarse_train, y_coarse_temp, y_fine_train, y_fine_temp = train_test_split(\n",
        "    X, y_coarse, y_fine, test_size=0.3, random_state=42\n",
        ")\n",
        "X_val, X_test, y_coarse_val, y_coarse_test, y_fine_val, y_fine_test = train_test_split(\n",
        "    X_temp, y_coarse_temp, y_fine_temp, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "splits = {\n",
        "    'train': (X_train, y_coarse_train, y_fine_train),\n",
        "    'val': (X_val, y_coarse_val, y_fine_val),\n",
        "    'test': (X_test, y_coarse_test, y_fine_test)\n",
        "}\n",
        "\n",
        "print(f\"Training size: {len(X_train)}\")\n",
        "print(f\"Validation size: {len(X_val)}\")\n",
        "print(f\"Test size: {len(X_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6b7lZB7aB5Y",
        "outputId": "41b88102-177c-481d-ec28-12c9b53c356d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training size: 586\n",
            "Validation size: 126\n",
            "Test size: 126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is successfully split. Now, we’ll create a PyTorch Dataset class to handle tokenized inputs and labels for efficient batching during training and evaluation.\n",
        "\n",
        "Step 4: Create a PyTorch Dataset Class"
      ],
      "metadata": {
        "id": "PQ8tFFD1aVoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = set(label for labels in pd.concat([y_coarse_train, y_coarse_val, y_coarse_test,\n",
        "                                                y_fine_train, y_fine_val, y_fine_test]) for label in labels)\n",
        "\n",
        "label_to_id = {label: idx for idx, label in enumerate(all_labels)}\n",
        "id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
        "\n",
        "print(\"Label to ID mapping:\", label_to_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2fUxNMJaWmX",
        "outputId": "bce37c0d-17e4-4350-cdf6-a07802ce0456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label to ID mapping: {'B-DEVELOPPEMENT': 0, 'I-ORGANE': 1, 'B-DESCRIPTEUR': 2, 'B-DISPOSITION': 3, 'I-COULEUR': 4, 'B-SURFACE': 5, 'I-DEVELOPPEMENT': 6, 'I-POSITION': 7, 'B-COULEUR': 8, 'B-POSITION': 9, 'I-DESCRIPTEUR': 10, 'B-ORGANE': 11, 'O': 12, 'I-STRUCTURE': 13, 'I-DISPOSITION': 14, 'I-MESURE': 15, 'B-STRUCTURE': 16, 'I-FORME': 17, 'B-FORME': 18, 'B-MESURE': 19, 'I-SURFACE': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6IoCtvWTbV_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = NERDataset(X_train, y_coarse_train, y_fine_train, tokenizer)\n",
        "val_dataset = NERDataset(X_val, y_coarse_val, y_fine_val, tokenizer)\n",
        "test_dataset = NERDataset(X_test, y_coarse_test, y_fine_test, tokenizer)\n",
        "\n",
        "sample = train_dataset[0]\n",
        "print(sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtgGyUotbPGQ",
        "outputId": "753a3610-972b-4cda-adb9-c76d35537f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([  101, 12098, 23736, 11393,  4887, 15068, 12098,  8286,  2618,  3449,\n",
            "         6651,  1010,  2139,  1015,  1011,  1019,  1049,  1025,  8223, 25639,\n",
            "        24665, 26741,  3269,  2063,  4372, 17579, 13665,  1043, 20470,  2890,\n",
            "         1010,  1037,  1048,  1005,  6453, 11968, 14876,  2483,  4078, 15333,\n",
            "        26639, 13433, 17854,  2229,  1025,  4315, 14862,  4372,  7913, 11231,\n",
            "         2094,  1081, 11721,  6826,  2072,  2139, 13433, 12146,  3802, 10448,\n",
            "         4244,  3802,  2139, 15718, 21225,  2015, 13433, 12146, 25320,  9307,\n",
            "         5602,  1010,  2556,  4630, 10861,  2140, 10997, 14925, 12502,  4244,\n",
            "        15191,  2229,  3802,  4937,  9331, 29598,  4244,  3802, 26692,  4570,\n",
            "         3802,  2000,  2102, 28353,  2226, 10997,  1025, 15333, 26639, 10768,\n",
            "        19231,  4244,  1037, 14255, 10483,  4221, 19044, 22573, 10768, 19231,\n",
            "         4244, 20146,  2015,  1010,  2177, 10285, 11968,  1017,  1011,  2260,\n",
            "         4372, 18404,  1011,  2310, 28228,  6895, 20434,   102]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), 'coarse_labels': tensor([11, 12, 11, 12, 12, 12, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 11, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 11,  2,  2,  2, 12, 11, 12, 11, 12, 12,\n",
            "        12, 12, 11, 11, 11,  2, 11, 11, 12, 12, 12, 11, 11, 11, 12, 12, 12, 12,\n",
            "        12, 12, 11, 12, 12, 12, 12, 12,  1, 12, 12, 12, 12, 12, 12, 12, 12,  2,\n",
            "         2,  2, 12, 12, 12, 12, 12, 12, 12, 11, 12, 12, 12, 11, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 11, 11, 12, 12, 12, 11, 11, 11,\n",
            "        12, 11, 11,  2, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,  2, 12,  2, 10,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12,  2,  2, 11, 11, 12, 12,  2, 12,  2, 12,\n",
            "        12, 12, 12,  2, 12, 12, 12, 12, 12, 12,  2, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 11, 11, 12, 12, 12, 12, 12, 12, 11, 11,  2,  2, 12, 12,\n",
            "        12, 12, 12, 12, 12,  2,  2,  2, 12, 11, 11, 12, 12, 12, 12, 11, 12,  2,\n",
            "        12, 12, 12, 12, 12,  2,  2, 12, 12, 12, 12, 12, 11, 11, 11, 11, 12, 11,\n",
            "        11, 12, 12,  2, 12, 12, 12, 12,  2,  2, 11, 12, 11, 12, 11,  1,  2, 12,\n",
            "        10, 12, 12, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 11,  2,  2,  2,  2,  2, 12, 12,  2, 12, 12,  2, 12,  2, 12,  2, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 11, 12, 12, 12, 12,  2,  2, 12, 12, 12,\n",
            "         2,  2, 12, 11, 11, 11, 12, 12, 11, 10,  2, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 11, 11, 12, 12, 12, 12, 12, 12, 12, 11, 11, 12, 12, 12, 12, 12, 11,\n",
            "        12, 12, 12, 12, 12, 12, 11,  2,  2,  2, 12, 12,  2,  2, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 11, 11, 12, 11, 10,  2, 11, 11, 12, 12, 12, 11, 11, 12,\n",
            "        12, 11, 11, 12, 12, 12, 12, 11, 11,  2,  2, 12, 11, 11, 12, 12, 12, 12,\n",
            "        11, 11, 11, 11, 12,  2, 11, 11, 12, 11,  1, 11, 12, 11, 11, 11, 11, 12,\n",
            "        12, 11, 11,  2,  2,  2, 12, 12,  2,  2, 12, 12,  2,  2, 12, 12, 11, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 11, 11,  2,  2,  2, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 11, 11, 11, 12, 12,  2, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12]), 'fine_labels': tensor([11, 12, 11, 12, 12, 12, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 11, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 11,  5,  5,  5, 12, 11, 12, 11, 12, 12,\n",
            "        12, 12, 11, 11, 11,  2, 11, 11, 12, 12, 12, 11, 11, 11, 12, 12, 12, 12,\n",
            "        12, 12, 11, 12, 12, 12, 12, 12,  1, 12, 12, 12, 12, 12, 12, 12, 12,  2,\n",
            "         2,  5, 12, 12, 12, 12, 12, 12, 12, 11, 12, 12, 12, 11, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 11, 11, 12, 12, 12, 11, 11, 11,\n",
            "        12, 11, 11, 16, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 18, 12,  2, 10,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12,  3,  3, 11, 11, 12, 12,  2, 12,  8, 12,\n",
            "        12, 12, 12,  2, 12, 12, 12, 12, 12, 12,  5, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 11, 11, 12, 12, 12, 12, 12, 12, 11, 11,  5,  5, 12, 12,\n",
            "        12, 12, 12, 12, 12,  9,  9,  9, 12, 11, 11, 12, 12, 12, 12, 11, 12,  9,\n",
            "        12, 12, 12, 12, 12,  2,  2, 12, 12, 12, 12, 12, 11, 11, 11, 11, 12, 11,\n",
            "        11, 12, 12,  5, 12, 12, 12, 12,  5,  5, 11, 12, 11, 12, 11,  1, 18, 12,\n",
            "         4, 12, 12, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 11, 18, 18, 18,  8,  8, 12, 12,  8, 12, 12,  8, 12,  8, 12,  8, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 11, 12, 12, 12, 12,  2,  2, 12, 12, 12,\n",
            "         2,  2, 12, 11, 11, 11, 12, 12, 11, 10,  2, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 11, 11, 12, 12, 12, 12, 12, 12, 12, 11, 11, 12, 12, 12, 12, 12, 11,\n",
            "        12, 12, 12, 12, 12, 12, 11,  2,  2,  2, 12, 12,  2,  2, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 11, 11, 12, 11, 10,  2, 11, 11, 12, 12, 12, 11, 11, 12,\n",
            "        12, 11, 11, 12, 12, 12, 12, 11, 11, 18, 18, 12, 11, 11, 12, 12, 12, 12,\n",
            "        11, 11, 11, 11, 12, 16, 11, 11, 12, 11,  1, 11, 12, 11, 11, 11, 11, 12,\n",
            "        12, 11, 11, 19, 19, 19, 12, 12,  2,  2, 12, 12,  2,  2, 12, 12, 11, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 11, 11, 18, 18, 18, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 11, 11, 11, 12, 12,  8, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
            "        12, 12, 12])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gpu_rEP7cCz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    input_ids = [item['input_ids'] for item in batch]\n",
        "    attention_masks = [item['attention_mask'] for item in batch]\n",
        "    coarse_labels = [item['coarse_labels'] for item in batch]  # Already tensors\n",
        "    fine_labels = [item['fine_labels'] for item in batch]      # Already tensors\n",
        "\n",
        "    # Pad sequences and labels to the longest in the batch\n",
        "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)  # Padding value for input IDs\n",
        "    attention_masks = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
        "    coarse_labels = pad_sequence(coarse_labels, batch_first=True, padding_value=label_to_id['O'])  # Padding value for labels\n",
        "    fine_labels = pad_sequence(fine_labels, batch_first=True, padding_value=label_to_id['O'])\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_masks,\n",
        "        'coarse_labels': coarse_labels,\n",
        "        'fine_labels': fine_labels\n",
        "    }\n",
        "\n",
        "# Update DataLoaders with the corrected collate_fn\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Check one batch from the train DataLoader\n",
        "for batch in train_loader:\n",
        "    print(batch)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRLg39n2cNPh",
        "outputId": "3ef04e07-1015-4cee-d931-7326c973baa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,  4958, 11514,  ...,  7505,  1014,   102],\n",
            "        [  101, 12810,  2063,  ..., 26639,  1010,   102],\n",
            "        [  101,  1054,  4048,  ...,  3126,  1010,   102],\n",
            "        ...,\n",
            "        [  101,  1054,  4048,  ...,  7505,  1018,   102],\n",
            "        [  101, 12098,  8286,  ...,  2015, 20146,   102],\n",
            "        [  101, 12098, 13578,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'coarse_labels': tensor([[12, 12, 12,  ..., 12, 12, 12],\n",
            "        [11, 12, 12,  ..., 12, 12, 12],\n",
            "        [11, 12,  2,  ..., 12, 12, 12],\n",
            "        ...,\n",
            "        [11, 12, 12,  ..., 12, 12, 12],\n",
            "        [11, 12, 12,  ..., 12, 12, 12],\n",
            "        [11, 12, 12,  ..., 12, 12, 12]]), 'fine_labels': tensor([[12, 12, 12,  ..., 12, 12, 12],\n",
            "        [11, 12, 12,  ..., 12, 12, 12],\n",
            "        [11, 12,  2,  ..., 12, 12, 12],\n",
            "        ...,\n",
            "        [11, 12, 12,  ..., 12, 12, 12],\n",
            "        [11, 12, 12,  ..., 12, 12, 12],\n",
            "        [11, 12, 12,  ..., 12, 12, 12]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The DataLoader is now working as expected, providing batches with properly padded sequences and labels. We are ready to move on to building the Vanilla RNN baseline model.\n",
        "\n",
        "Step 6: Build the Vanilla RNN Baseline Model"
      ],
      "metadata": {
        "id": "r6aVhWoocdjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class VanillaRNNNERModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, padding_idx=0):\n",
        "        super(VanillaRNNNERModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        embedded = self.embedding(input_ids)\n",
        "\n",
        "        rnn_output, _ = self.rnn(embedded)\n",
        "\n",
        "        logits = self.fc(rnn_output)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "T5uiTT1Xcek8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Define the Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "MizSMfeTc4Py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = tokenizer.vocab_size\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = len(label_to_id)\n",
        "PADDING_IDX = tokenizer.pad_token_id\n",
        "\n",
        "model = VanillaRNNNERModel(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    output_dim=OUTPUT_DIM,\n",
        "    padding_idx=PADDING_IDX\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=label_to_id['O'])\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "print(\"Model, loss function, and optimizer initialized!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-_llZMGc5S_",
        "outputId": "ef6dad1c-5be8-4a79-f424-e206ad4891ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model, loss function, and optimizer initialized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Define the Training Loop\n",
        "Now, we will create the training loop to train the Vanilla RNN model on the training data.\n",
        "\n",
        "Training Loop Code"
      ],
      "metadata": {
        "id": "CTSdHKzjdN4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            coarse_labels = batch['coarse_labels'].to(device)  # Coarse-grained labels\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(input_ids, attention_mask)  # Shape: (batch_size, seq_len, output_dim)\n",
        "\n",
        "            # Reshape logits and labels\n",
        "            batch_size, seq_len, num_classes = logits.size()\n",
        "            logits = logits.view(-1, num_classes)\n",
        "            coarse_labels = coarse_labels.view(-1)\n",
        "            attention_mask = attention_mask.view(-1)\n",
        "\n",
        "            # Masking valid tokens\n",
        "            active_indices = torch.nonzero(attention_mask).squeeze()\n",
        "            active_logits = logits[active_indices]\n",
        "            active_labels = coarse_labels[active_indices]\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(active_logits, active_labels)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Backward pass and optimizer step\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                coarse_labels = batch['coarse_labels'].to(device)\n",
        "\n",
        "                logits = model(input_ids, attention_mask)\n",
        "\n",
        "                # Reshape logits and labels\n",
        "                batch_size, seq_len, num_classes = logits.size()\n",
        "                logits = logits.view(-1, num_classes)\n",
        "                coarse_labels = coarse_labels.view(-1)\n",
        "                attention_mask = attention_mask.view(-1)\n",
        "\n",
        "                # Masking valid tokens\n",
        "                active_indices = torch.nonzero(attention_mask).squeeze()\n",
        "                active_logits = logits[active_indices]\n",
        "                active_labels = coarse_labels[active_indices]\n",
        "\n",
        "                loss = criterion(active_logits, active_labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        # Calculate average losses\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "        print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "# Call the training function\n",
        "train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QeQ5YpsdO-y",
        "outputId": "37f1637b-4940-420f-f09a-38af578f722b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Training Loss: 1.3227\n",
            "Validation Loss: 0.9620\n",
            "Epoch 2/5\n",
            "Training Loss: 0.9801\n",
            "Validation Loss: 0.9535\n",
            "Epoch 3/5\n",
            "Training Loss: 0.9922\n",
            "Validation Loss: 0.9701\n",
            "Epoch 4/5\n",
            "Training Loss: 0.9774\n",
            "Validation Loss: 0.9518\n",
            "Epoch 5/5\n",
            "Training Loss: 0.9843\n",
            "Validation Loss: 0.9566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training has successfully completed! The training and validation losses indicate that the model is learning, but there might be some slight overfitting or stagnation in validation loss improvements after a few epochs. This could be addressed with hyperparameter tuning or regularization techniques.\n",
        "\n",
        "Next Step: Evaluate the Model\n",
        "Now, let’s calculate evaluation metrics on the test set. We’ll use:\n",
        "\n",
        "Token-Level Accuracy: Percentage of correctly predicted tokens.\n",
        "F1 Score, Precision, Recall: Using classification metrics."
      ],
      "metadata": {
        "id": "L7GS14vlepNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Code"
      ],
      "metadata": {
        "id": "kEeT-TYWeqQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            coarse_labels = batch['coarse_labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            logits = model(input_ids, attention_mask)\n",
        "\n",
        "            # Reshape logits and labels\n",
        "            batch_size, seq_len, num_classes = logits.size()\n",
        "            logits = logits.view(-1, num_classes)\n",
        "            coarse_labels = coarse_labels.view(-1)\n",
        "            attention_mask = attention_mask.view(-1)\n",
        "\n",
        "            # Mask padding tokens\n",
        "            active_indices = torch.nonzero(attention_mask).squeeze()\n",
        "            active_logits = logits[active_indices]\n",
        "            active_labels = coarse_labels[active_indices]\n",
        "\n",
        "            # Compute loss\n",
        "            loss = criterion(active_logits, active_labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Get predictions\n",
        "            predictions = torch.argmax(active_logits, dim=1).cpu().numpy()\n",
        "            labels = active_labels.cpu().numpy()\n",
        "\n",
        "            all_predictions.extend(predictions)\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
        "\n",
        "    # Get unique classes in the test set\n",
        "    unique_labels = sorted(set(all_labels))\n",
        "    target_names = [id_to_label[label] for label in unique_labels]\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(\n",
        "        all_labels, all_predictions, labels=unique_labels, target_names=target_names\n",
        "    )\n",
        "    print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, test_loader, criterion, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mtNKE2Pes7B",
        "outputId": "93833c11-4ca3-4926-e030-fdae1eefd93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.9697\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     I-ORGANE       0.00      0.00      0.00        90\n",
            "B-DESCRIPTEUR       0.07      1.00      0.14      1137\n",
            "I-DESCRIPTEUR       0.00      0.00      0.00       107\n",
            "     B-ORGANE       0.12      0.01      0.02      1188\n",
            "            O       0.00      0.00      0.00     12974\n",
            "\n",
            "     accuracy                           0.07     15496\n",
            "    macro avg       0.04      0.20      0.03     15496\n",
            " weighted avg       0.01      0.07      0.01     15496\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's performance is very low, which indicates that it is struggling to learn the task. Here’s a breakdown of the results and some potential next steps to improve performance.\n",
        "\n",
        "Analysis of Results\n",
        "Accuracy:\n",
        "\n",
        "Overall accuracy is very low (0.07), which is indicative of poor predictions.\n",
        "Class Imbalance:\n",
        "\n",
        "The majority of the dataset consists of the 'O' class (non-entity tokens), which skews the weighted metrics.\n",
        "Classes like I-ORGANE and B-ORGANE are underrepresented, causing the model to fail to learn these labels.\n",
        "Warnings:\n",
        "\n",
        "The UndefinedMetricWarning occurs because some classes (I-ORGANE, I-DESCRIPTEUR, O) have no predicted samples, leading to precision being undefined."
      ],
      "metadata": {
        "id": "PSk2Tb9FfRX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improvement"
      ],
      "metadata": {
        "id": "qOAB3vIbfTa2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Class Weights to the Loss Function\n",
        "The first improvement is to address class imbalance by adding class weights to the CrossEntropyLoss. This will penalize misclassifications for rare classes more heavily."
      ],
      "metadata": {
        "id": "PfL7cf7qfg21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "all_coarse_labels = torch.cat([batch['coarse_labels'].view(-1) for batch in train_loader])\n",
        "\n",
        "class_counts = np.bincount(all_coarse_labels.cpu().numpy(), minlength=len(label_to_id))\n",
        "class_weights = np.where(class_counts == 0, 1e6, 1.0 / class_counts)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights, ignore_index=label_to_id['O'])\n",
        "\n",
        "print(\"Class weights applied to the loss function:\", class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MYClRjCfj8E",
        "outputId": "47083422-492f-4981-8efb-03e199211f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights applied to the loss function: tensor([1.0000e+06, 6.3898e-04, 5.2359e-05, 1.0000e+06, 1.0000e+06, 1.0000e+06,\n",
            "        1.0000e+06, 1.0000e+06, 1.0000e+06, 1.0000e+06, 5.7078e-04, 5.1733e-05,\n",
            "        4.2526e-06, 1.0000e+06, 1.0000e+06, 1.0000e+06, 1.0000e+06, 1.0000e+06,\n",
            "        1.0000e+06, 1.0000e+06, 1.0000e+06])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-8f7e985f5e60>:7: RuntimeWarning: divide by zero encountered in divide\n",
            "  class_weights = np.where(class_counts == 0, 1e6, 1.0 / class_counts)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The class weights are now applied correctly, with zero-count classes assigned a high weight of 1*10**6 . The RuntimeWarning is harmless because we explicitly handle zero counts with np.where.\n",
        "\n",
        "Next Step: Re-Train the Model\n",
        "Now that the class weights are set, you can re-train the model using the updated criterion. Use the same training loop as before:"
      ],
      "metadata": {
        "id": "mMw8Zyzwh7pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saURKl5giWcM",
        "outputId": "2f589f89-6832-4017-9e3f-8a630b4d14c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Training Loss: 1.4919\n",
            "Validation Loss: 1.4521\n",
            "Epoch 2/5\n",
            "Training Loss: 1.4062\n",
            "Validation Loss: 1.3919\n",
            "Epoch 3/5\n",
            "Training Loss: 1.4105\n",
            "Validation Loss: 1.4069\n",
            "Epoch 4/5\n",
            "Training Loss: 1.3940\n",
            "Validation Loss: 1.3972\n",
            "Epoch 5/5\n",
            "Training Loss: 1.3965\n",
            "Validation Loss: 1.3866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model has successfully re-trained with class weights, and the losses (both training and validation) indicate the model is learning but slowly improving. Next, we’ll evaluate the model again to check how the class weights have influenced its performance.\n",
        "\n",
        "Next Step: Evaluate the Model\n",
        "Run the updated evaluation function to calculate metrics for the test set:"
      ],
      "metadata": {
        "id": "GbltR5jWis8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, test_loader, criterion, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TbjcQpEiuf3",
        "outputId": "681aed74-91f4-4a8b-fd83-8eef4ec74fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.3880\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     I-ORGANE       0.00      0.00      0.00        90\n",
            "B-DESCRIPTEUR       0.00      0.00      0.00      1137\n",
            "I-DESCRIPTEUR       0.00      0.00      0.00       107\n",
            "     B-ORGANE       0.08      1.00      0.14      1188\n",
            "            O       0.00      0.00      0.00     12974\n",
            "\n",
            "     accuracy                           0.08     15496\n",
            "    macro avg       0.02      0.20      0.03     15496\n",
            " weighted avg       0.01      0.08      0.01     15496\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results indicate minimal improvement in model performance, with most metrics still poor. The key observations are:\n",
        "\n",
        "Observations\n",
        "Class Imbalance Impact:\n",
        "\n",
        "Class weights enabled the model to predict the class B-ORGANE better (recall is 1.00), but it significantly struggles with other classes, including O.\n",
        "Undefined Precision/Recall:\n",
        "\n",
        "Many classes (I-ORGANE, B-DESCRIPTEUR, I-DESCRIPTEUR) have no predicted samples, causing precision to be undefined.\n",
        "Overall F1 Score:\n",
        "\n",
        "Still very low due to the trade-off between improving rare class performance and the model's inability to handle the majority class (O)."
      ],
      "metadata": {
        "id": "_YE34DDBkTmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace Vanilla RNN with LSTM\n",
        "Replacing the Vanilla RNN with an LSTM should improve the model's ability to capture long-term dependencies, which is critical for Named Entity Recognition."
      ],
      "metadata": {
        "id": "M4gtiQdOkU1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMNERModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, padding_idx=0):\n",
        "        super(LSTMNERModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        embedded = self.embedding(input_ids)\n",
        "\n",
        "        lstm_output, _ = self.lstm(embedded)\n",
        "\n",
        "        logits = self.fc(lstm_output)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "_LG_S39QkYrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "Bidirectional LSTM:\n",
        "\n",
        "The LSTM processes sequences in both forward and backward directions, improving context understanding.\n",
        "The hidden state size is doubled (hidden_dim * 2).\n",
        "Embedding Layer:\n",
        "\n",
        "Remains unchanged, converting token IDs to dense vectors.\n",
        "Fully Connected Layer:\n",
        "\n",
        "Maps the concatenated hidden states from the bidirectional LSTM to the output dimension."
      ],
      "metadata": {
        "id": "pTJJI4uck1Ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMNERModel(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    output_dim=OUTPUT_DIM,\n",
        "    padding_idx=PADDING_IDX\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "m7u4XffVk26G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGap66dKk7jU",
        "outputId": "88e5a933-c896-4e16-82a4-7439faa204c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Training Loss: 3.0374\n",
            "Validation Loss: 3.0376\n",
            "Epoch 2/5\n",
            "Training Loss: 3.0364\n",
            "Validation Loss: 3.0376\n",
            "Epoch 3/5\n",
            "Training Loss: 3.0363\n",
            "Validation Loss: 3.0376\n",
            "Epoch 4/5\n",
            "Training Loss: 3.0363\n",
            "Validation Loss: 3.0376\n",
            "Epoch 5/5\n",
            "Training Loss: 3.0366\n",
            "Validation Loss: 3.0376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybqTuVUqlobs",
        "outputId": "1c267d9a-bb9d-42cd-b1ad-db8a3d633fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Training Loss: 2.9412\n",
            "Validation Loss: 2.8167\n",
            "Epoch 2/5\n",
            "Training Loss: 2.3909\n",
            "Validation Loss: 1.4680\n",
            "Epoch 3/5\n",
            "Training Loss: 1.4100\n",
            "Validation Loss: 1.3960\n",
            "Epoch 4/5\n",
            "Training Loss: 1.3985\n",
            "Validation Loss: 1.3968\n",
            "Epoch 5/5\n",
            "Training Loss: 1.3961\n",
            "Validation Loss: 1.3938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, test_loader, criterion, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h58WFBlTmI_3",
        "outputId": "21516bd1-029e-42ee-ac0b-c12c471b5ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.3938\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     I-ORGANE       0.00      0.08      0.01        90\n",
            "B-DESCRIPTEUR       0.08      0.40      0.13      1137\n",
            "I-DESCRIPTEUR       0.01      0.49      0.01       107\n",
            "     B-ORGANE       0.08      0.06      0.07      1188\n",
            "            O       0.00      0.00      0.00     12974\n",
            "\n",
            "     accuracy                           0.04     15496\n",
            "    macro avg       0.03      0.20      0.04     15496\n",
            " weighted avg       0.01      0.04      0.01     15496\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's performance has slightly improved in terms of precision and recall for some classes, such as B-DESCRIPTEUR and I-DESCRIPTEUR, but the overall results are still not satisfactory. This suggests the model architecture or the features provided are not sufficient to handle the complexity of the task.\n",
        "\n",
        "Next Steps\n",
        "To further improve, we can incorporate pretrained embeddings (such as BERT) into the model. Pretrained embeddings will give the model a stronger foundation for understanding token-level relationships, which can lead to significant performance improvements.\n",
        "\n",
        "Step 3: Use BERT Embeddings"
      ],
      "metadata": {
        "id": "_gmoeRXUmUBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "class BERTLSTMNERModel(nn.Module):\n",
        "    def __init__(self, bert_model_name, hidden_dim, output_dim):\n",
        "        super(BERTLSTMNERModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        self.lstm = nn.LSTM(self.bert.config.hidden_size, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        embeddings = bert_output.last_hidden_state\n",
        "\n",
        "        lstm_output, _ = self.lstm(embeddings)\n",
        "\n",
        "        logits = self.fc(lstm_output)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "NjUVb-opmVWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT Model:\n",
        "\n",
        "The pretrained BERT model generates token embeddings.\n",
        "We use the last_hidden_state as input to the LSTM layer.\n",
        "LSTM Layer:\n",
        "\n",
        "Processes the contextualized embeddings for token-level predictions.\n",
        "Output Layer:\n",
        "\n",
        "Maps the LSTM outputs to the label space.\n",
        "Next Steps:\n",
        "Replace the existing model with BERTLSTMNERModel:"
      ],
      "metadata": {
        "id": "kKk86Eq1mifx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BERTLSTMNERModel(bert_model_name='bert-base-uncased', hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "30e8d4b7e03444799345f05c725209f0",
            "5d8d34163ef248acb2783dd57c58388d",
            "b56c94aacde84ca98b1389a3144cb644",
            "bb387137536545e3aa0e452a90f35f1e",
            "164da97254194c3bbbb2a43e361aded2",
            "385f55505f594e80af8eb32d2873ccea",
            "39a7bff8666146b9881025b2b650c0a5",
            "836c536ad8d145b783aebf151ad8185d",
            "bfebe80ec0b7446e99bceabb47c7d061",
            "3b86ed2c5490479baaaea78fe3732bd4",
            "160569a9cdbd4d7b9829a35d59988d2e"
          ]
        },
        "id": "VlMsfsFZmiqq",
        "outputId": "29488a88-057f-495a-f349-b82e4db4a131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30e8d4b7e03444799345f05c725209f0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58EP6NG6mv-I",
        "outputId": "98965e3e-7567-4c50-fb0c-4244773f2f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Training Loss: 3.0460\n",
            "Validation Loss: 3.0511\n",
            "Epoch 2/5\n",
            "Training Loss: 3.0456\n",
            "Validation Loss: 3.0511\n",
            "Epoch 3/5\n",
            "Training Loss: 3.0466\n",
            "Validation Loss: 3.0511\n",
            "Epoch 4/5\n",
            "Training Loss: 3.0471\n",
            "Validation Loss: 3.0511\n",
            "Epoch 5/5\n",
            "Training Loss: 3.0459\n",
            "Validation Loss: 3.0511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW([\n",
        "    {'params': model.bert.parameters(), 'lr': 1e-5},\n",
        "    {'params': model.lstm.parameters(), 'lr': 1e-4},\n",
        "    {'params': model.fc.parameters(), 'lr': 1e-4}\n",
        "])\n",
        "\n",
        "train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db8uBb5h3YVw",
        "outputId": "924800a5-2f6e-406f-b122-af9f9280c76e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Training Loss: 1.8755\n",
            "Validation Loss: 1.4176\n",
            "Epoch 2/5\n",
            "Training Loss: 1.4098\n",
            "Validation Loss: 1.3923\n",
            "Epoch 3/5\n",
            "Training Loss: 1.4087\n",
            "Validation Loss: 1.3899\n",
            "Epoch 4/5\n",
            "Training Loss: 1.3991\n",
            "Validation Loss: 1.4124\n",
            "Epoch 5/5\n",
            "Training Loss: 1.4013\n",
            "Validation Loss: 1.4011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The differential learning rate strategy has improved the training process, as indicated by a significant reduction in both training and validation losses, especially in the early epochs. However, the model's performance is now showing signs of stagnation or slight overfitting in later epochs, as the validation loss no longer decreases.\n",
        "\n",
        "Next Step: Evaluate the Model on the Test Set\n",
        "Let’s evaluate the updated model to check its performance on the test set."
      ],
      "metadata": {
        "id": "UcvlAh1_Nu92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, test_loader, criterion, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPE8OAfSNwke",
        "outputId": "6cc19f97-1dc7-4beb-8486-4a5cf999d489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.3919\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     I-ORGANE       0.00      0.00      0.00        90\n",
            "B-DESCRIPTEUR       0.00      0.00      0.00      1137\n",
            "I-DESCRIPTEUR       0.01      0.98      0.01       107\n",
            "     B-ORGANE       0.08      0.04      0.05      1188\n",
            "            O       0.00      0.00      0.00     12974\n",
            "\n",
            "     accuracy                           0.01     15496\n",
            "    macro avg       0.02      0.20      0.01     15496\n",
            " weighted avg       0.01      0.01      0.00     15496\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test results indicate that the model is still underperforming significantly, particularly for the majority class (O) and key entity classes. Despite the changes, the metrics show that the model is not learning the task effectively.\n",
        "\n",
        "Key Observations\n",
        "Low Precision and Recall for Most Classes:\n",
        "\n",
        "The model struggles to predict most classes, with only slight improvement in I-DESCRIPTEUR.\n",
        "Imbalanced Dataset Challenge:\n",
        "\n",
        "The imbalance in the dataset remains a significant issue, as the model tends to ignore rare classes in favor of overrepresented ones (though this is not fully effective either).\n",
        "Validation-Test Disparity:\n",
        "\n",
        "While the validation loss decreases, the test performance indicates that the model is not generalizing well.\n",
        "Suggestions for Further Improvement\n",
        "1. Use a Transformer-Based Sequence Labeling Model (Directly)\n",
        "Instead of combining BERT with LSTM, directly fine-tune a pretrained Transformer model like BERT, DistilBERT, or RoBERTa for sequence labeling.\n",
        "Hugging Face's transformers library provides a prebuilt BertForTokenClassification class tailored for such tasks.\n",
        "Code to Use BERT for Token Classification"
      ],
      "metadata": {
        "id": "v6yBtB_TOTqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in train_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            coarse_labels = batch['coarse_labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            batch_size, seq_len, num_classes = logits.size()\n",
        "            logits = logits.view(-1, num_classes)\n",
        "            coarse_labels = coarse_labels.view(-1)\n",
        "            attention_mask = attention_mask.view(-1)\n",
        "\n",
        "\n",
        "            active_indices = attention_mask.nonzero(as_tuple=True)[0]\n",
        "            active_logits = logits[active_indices]\n",
        "            active_labels = coarse_labels[active_indices]\n",
        "\n",
        "\n",
        "            loss = criterion(active_logits, active_labels)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                coarse_labels = batch['coarse_labels'].to(device)\n",
        "\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                logits = outputs.logits\n",
        "\n",
        "                batch_size, seq_len, num_classes = logits.size()\n",
        "                logits = logits.view(-1, num_classes)\n",
        "                coarse_labels = coarse_labels.view(-1)\n",
        "                attention_mask = attention_mask.view(-1)\n",
        "\n",
        "                active_indices = attention_mask.nonzero(as_tuple=True)[0]\n",
        "                active_logits = logits[active_indices]\n",
        "                active_labels = coarse_labels[active_indices]\n",
        "\n",
        "                loss = criterion(active_logits, active_labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "        print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "RWPt5xU9Orof",
        "outputId": "369dc7ef-0db1-4cd3-c7ff-0672e3135d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Training Loss: 1.1921\n",
            "Validation Loss: 0.9823\n",
            "Epoch 2/5\n",
            "Training Loss: 1.0033\n",
            "Validation Loss: 0.9656\n",
            "Epoch 3/5\n",
            "Training Loss: 0.9908\n",
            "Validation Loss: 0.9685\n",
            "Epoch 4/5\n",
            "Training Loss: 0.9987\n",
            "Validation Loss: 0.9846\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-64a5762987c4>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation Loss: {avg_val_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-64a5762987c4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, device, epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1863\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1143\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    693\u001b[0m                 )\n\u001b[1;32m    694\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    696\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training and validation losses have significantly improved with this update, indicating that the model is now learning better with the Transformer-based architecture. However, the slight increase in validation loss in later epochs suggests the model may start overfitting."
      ],
      "metadata": {
        "id": "kBmpCOOTfbXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            coarse_labels = batch['coarse_labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            batch_size, seq_len, num_classes = logits.size()\n",
        "            logits = logits.view(-1, num_classes)\n",
        "            coarse_labels = coarse_labels.view(-1)\n",
        "            attention_mask = attention_mask.view(-1)\n",
        "\n",
        "            active_indices = attention_mask.nonzero(as_tuple=True)[0]\n",
        "            active_logits = logits[active_indices]\n",
        "            active_labels = coarse_labels[active_indices]\n",
        "\n",
        "            loss = criterion(active_logits, active_labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            predictions = torch.argmax(active_logits, dim=1).cpu().numpy()\n",
        "            labels = active_labels.cpu().numpy()\n",
        "\n",
        "            all_predictions.extend(predictions)\n",
        "            all_labels.extend(labels)\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_loader)\n",
        "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
        "\n",
        "    unique_labels = sorted(set(all_labels))\n",
        "    target_names = [id_to_label[label] for label in unique_labels]\n",
        "    report = classification_report(\n",
        "        all_labels, all_predictions, labels=unique_labels, target_names=target_names\n",
        "    )\n",
        "    print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "id": "UFNWfDRlOU1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, test_loader, criterion, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g1zIe8GeXxu",
        "outputId": "e7b251a7-2946-4718-bbb3-4e39ee46f0bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.9851\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     I-ORGANE       0.00      0.00      0.00        90\n",
            "B-DESCRIPTEUR       0.00      0.00      0.00      1137\n",
            "I-DESCRIPTEUR       0.00      0.00      0.00       107\n",
            "     B-ORGANE       0.08      1.00      0.14      1188\n",
            "            O       0.00      0.00      0.00     12974\n",
            "\n",
            "     accuracy                           0.08     15496\n",
            "    macro avg       0.02      0.20      0.03     15496\n",
            " weighted avg       0.01      0.08      0.01     15496\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the entire model"
      ],
      "metadata": {
        "id": "xLzcZhsmezna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = \"model.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bUUZi1neu0q",
        "outputId": "d7746591-28ed-4e18-acec-8569846d332c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('coarse-and-fine-grained-ner-dataset.csv')\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "df['Coarse-grained Annotation'] = df['Coarse-grained Annotation'].apply(ast.literal_eval)\n",
        "\n",
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    text = row['Text']\n",
        "    annotations = row['Coarse-grained Annotation']\n",
        "\n",
        "    token_labels = ['O'] * len(text.split())\n",
        "\n",
        "    for start, end, label in annotations:\n",
        "        annotated_text = text[start:end].split()\n",
        "        for idx, token in enumerate(text.split()):\n",
        "            if token in annotated_text:\n",
        "                token_labels[idx] = f\"B-{label}\" if idx == 0 else f\"I-{label}\"\n",
        "\n",
        "    sentences.append(text.split())\n",
        "    labels.append(token_labels)\n",
        "\n",
        "unique_labels = sorted(set(label for sentence_labels in labels for label in sentence_labels))\n",
        "label_to_id = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "id_to_label = {idx: label for label, idx in label_to_id.items()}\n",
        "\n",
        "numerical_labels = [[label_to_id[label] for label in sentence_labels] for sentence_labels in labels]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentences, numerical_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Number of training sentences: {len(X_train)}\")\n",
        "print(f\"Number of testing sentences: {len(X_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8Og9r8aftlo",
        "outputId": "e59cbe85-b243-48a5-fac2-7f5cb89c0512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text  \\\n",
            "0   grandes feuilles opposées, oblongues-elliptiq...   \n",
            "1   feuilles opposées, groupées à l'extrémité des...   \n",
            "2   feuilles opposées, obovées oblongues, arrondi...   \n",
            "3   arbustes  petites feuilles opposées, groupées...   \n",
            "4   arbustes  feuilles opposées ou alternes, obla...   \n",
            "\n",
            "                                      Organ Entities  \\\n",
            "0  ['bouton', 'pédicelle', 'corolle', 'tube', 'fe...   \n",
            "1  ['limbe', 'style', 'filets', 'rameaux', 'sépal...   \n",
            "2  ['corolle', 'limbe', 'ovaire', 'lobes', 'base'...   \n",
            "3  ['anthères', 'pétales', 'tube', 'feuilles', 's...   \n",
            "4  ['base', 'nervure', 'feuilles', 'arbustes', 'l...   \n",
            "\n",
            "                                 Descriptor Entities  \\\n",
            "0  ['fermée', 'pubes-cents', 'cunéiformes', 'vent...   \n",
            "1  ['elliptiques', '1 cm de longueur', 'extrorses...   \n",
            "2  ['cunéiforme', '10,5 mm de longueur', 'long', ...   \n",
            "3  ['secondaires', 'accusé', 'saillantes', 'apicu...   \n",
            "4  ['proéminente', 'décurrente', 'alternes', 'obl...   \n",
            "\n",
            "                           Coarse-grained Annotation  \\\n",
            "0  [(650, 661, 'DESCRIPTEUR'), (968, 977, 'DESCRI...   \n",
            "1  [(609, 618, 'DESCRIPTEUR'), (129, 144, 'DESCRI...   \n",
            "2  [(60, 64, 'ORGANE'), (196, 205, 'DESCRIPTEUR')...   \n",
            "3  [(949, 959, 'DESCRIPTEUR'), (88, 105, 'DESCRIP...   \n",
            "4  [(140, 150, 'DESCRIPTEUR'), (32, 40, 'DESCRIPT...   \n",
            "\n",
            "                             Fine-grained Annotation  \n",
            "0  [(650, 661, 'DESCRIPTEUR'), (395, 407, 'DISPOS...  \n",
            "1  [(609, 618, 'DESCRIPTEUR'), (73, 80, 'FORME'),...  \n",
            "2  [(60, 64, 'ORGANE'), (180, 187, 'ORGANE'), (11...  \n",
            "3  [(949, 959, 'DESCRIPTEUR'), (88, 105, 'DESCRIP...  \n",
            "4  [(42, 54, 'FORME'), (119, 129, 'FORME'), (1, 9...  \n",
            "Number of training sentences: 670\n",
            "Number of testing sentences: 168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, sentences, labels, tokenizer, max_len):\n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoded = self.tokenizer(\n",
        "            self.sentences[idx],\n",
        "            is_split_into_words=True,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        word_ids = encoded.word_ids()\n",
        "        label_ids = []\n",
        "        for word_id in word_ids:\n",
        "            if word_id is None:\n",
        "                label_ids.append(-100)\n",
        "            else:\n",
        "                label_ids.append(self.labels[idx][word_id])\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoded['input_ids'].squeeze(),\n",
        "            'attention_mask': encoded['attention_mask'].squeeze(),\n",
        "            'labels': torch.tensor(label_ids)\n",
        "        }\n",
        "\n",
        "# creating datasets and DataLoaders\n",
        "train_dataset = NERDataset(X_train, y_train, tokenizer, max_len)\n",
        "test_dataset = NERDataset(X_test, y_test, tokenizer, max_len)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "for batch in train_loader:\n",
        "    print(batch.keys())\n",
        "    print(batch['input_ids'].shape, batch['attention_mask'].shape, batch['labels'].shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILl_dqTXgS5G",
        "outputId": "e0875e4e-ac5c-4f14-8024-4c0cb7314a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
            "torch.Size([16, 128]) torch.Size([16, 128]) torch.Size([16, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForTokenClassification\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# model\n",
        "num_labels = len(label_to_id)\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=num_labels).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Training\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "# Saving model\n",
        "model_save_path = \"bert_ner_model.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk3PL3Z2itii",
        "outputId": "8eb7513a-2979-4018-9451-c0e6d6d9aea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Training Loss: 0.5465\n",
            "Epoch [2/5], Training Loss: 0.1675\n",
            "Epoch [3/5], Training Loss: 0.0957\n",
            "Epoch [4/5], Training Loss: 0.0612\n",
            "Epoch [5/5], Training Loss: 0.0488\n",
            "Model saved to bert_ner_model.pth\n"
          ]
        }
      ]
    }
  ]
}